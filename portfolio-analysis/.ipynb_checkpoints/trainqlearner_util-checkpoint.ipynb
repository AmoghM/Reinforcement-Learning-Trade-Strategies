{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas  as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import data_process as d\n",
    "import pandas_datareader.data as web # fetch stock data\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q table initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_q_mat(all_states, all_actions):\n",
    "    '''\n",
    "    Initialize Q-table\n",
    "    Inputs:\n",
    "    all_states: a list of all the states values\n",
    "    all_actions: a dictionary of all possible actions to take\n",
    "    Output: \n",
    "    q_mat: randomly initialized Q-table\n",
    "    '''\n",
    "    states_size = len(all_states)\n",
    "    actions_size = len(all_actions)\n",
    "    \n",
    "    q_mat = np.random.rand(states_size, actions_size)/1e9\n",
    "    q_mat = pd.DataFrame(q_mat, columns=all_actions.keys())\n",
    "    \n",
    "    q_mat['states'] = all_states\n",
    "    q_mat.set_index('states', inplace=True)\n",
    "    \n",
    "    return q_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate action signal (0:sit, 1:buy, 2:sell) based on the action policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def act(state, q_mat, threshold=0.2, actions_size=3):\n",
    "    '''\n",
    "    Taking an action based on different strategies: \n",
    "    either random pick actions or take the actions \n",
    "    with the highest future return\n",
    "    Inputs:\n",
    "    state(str)\n",
    "    q_mat(dataframe): Q-table\n",
    "    threshold(float): the percentage of picking a random action\n",
    "    action_size(int): number of possible actions \n",
    "    Output:\n",
    "    action(int)\n",
    "    '''\n",
    "    if np.random.uniform(0,1) < threshold: # go random\n",
    "        action = np.random.randint(low=0, high=actions_size)  \n",
    "    else:\n",
    "        action = np.argmax(q_mat.loc[state].values)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_return_since_entry(bought_history, current_adj_close):\n",
    "    '''\n",
    "    Calculate the returns of current share holdings.\n",
    "    Inputs:\n",
    "    bought_history(list) \n",
    "    current_adj_close(float)\n",
    "    current_day(int)\n",
    "    Output:\n",
    "    return_since_entry(float)\n",
    "    '''\n",
    "    return_since_entry = 0.\n",
    "    \n",
    "    for b in bought_history:\n",
    "        return_since_entry += (current_adj_close - b)\n",
    "    return return_since_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_results(actions_history, returns_since_entry):\n",
    "    '''\n",
    "    Visualize the trading results with 2 plots\n",
    "    The upper plot shows the return since entry\n",
    "    The lower plot shows the action signal\n",
    "    Inputs:\n",
    "    actions_history(dict): has everydays' actions and close price\n",
    "    returns_since_entry(list): contains every day's return since entry\n",
    "    Output:\n",
    "    None\n",
    "    '''\n",
    "    f, (ax1, ax2) = plt.subplots(2, 1, figsize=(15,12))\n",
    "    \n",
    "    ax1.plot(returns_since_entry)\n",
    "    \n",
    "    days, prices, actions = [], [], []\n",
    "    for d, p, a in actions_history:\n",
    "        days.append(d)\n",
    "        prices.append(p)\n",
    "        actions.append(a)\n",
    "\n",
    "    #ax2.figure(figsize=(20,10))\n",
    "    ax2.plot(days, prices, label='normalized adj close price')\n",
    "    hold_d, hold_p, buy_d, buy_p, sell_d, sell_p = [], [], [], [], [], []\n",
    "    for d, p, a in actions_history:\n",
    "        if a == 0:\n",
    "            hold_d.append(d)\n",
    "            hold_p.append(p)\n",
    "        if a == 1:\n",
    "            buy_d.append(d)\n",
    "            buy_p.append(p)\n",
    "        if a == 2:\n",
    "            sell_d.append(d)\n",
    "            sell_p.append(p)\n",
    "        # ax2.annotate(all_actions[a], xy=(d,p), xytext=(d-.2, p+0.001), color=color, arrowprops=dict(arrowstyle='->',connectionstyle='arc3'))\n",
    "    ax2.scatter(hold_d, hold_p, color='blue', label='hold')\n",
    "    ax2.scatter(buy_d, buy_p, color='green', label='buy')\n",
    "    ax2.scatter(sell_d, sell_p, color='red', label='sell')\n",
    "    ax2.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_invested_capital(actions_history, returns_since_entry):\n",
    "    '''\n",
    "    Calculate the max capital being continously invested by the trader\n",
    "    Input:\n",
    "    actions_history(dict): has everydays' actions and close price\n",
    "    returns_since_entry(list): contains every day's return since entry\n",
    "    Output:\n",
    "    return_invest_ratio(float)\n",
    "    '''\n",
    "    invest = []\n",
    "    total = 0\n",
    "    return_invest_ratio = None\n",
    "    for i in range(len(actions_history)):\n",
    "        a = actions_history[i][2]\n",
    "        p = actions_history[i][1]\n",
    "\n",
    "        try:\n",
    "            next_a = actions_history[i+1][2]\n",
    "        except:\n",
    "            break\n",
    "        if a == 1:\n",
    "            total += p\n",
    "            if next_a != 1 or (i==len(actions_history)-2 and next_a==1):\n",
    "                invest.append(total)\n",
    "                total = 0\n",
    "    if invest:\n",
    "        return_invest_ratio = returns_since_entry[-1]/max(invest)\n",
    "        print('invested capital {}, return/invest ratio {}'.format(max(invest), return_invest_ratio))\n",
    "    else:\n",
    "        print('no buy transactions, invalid training')\n",
    "    return return_invest_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_base_return(data):\n",
    "    '''\n",
    "    Calculate the benchmark returns of a given stock\n",
    "    Input:\n",
    "    data(dataframe): containing normalized close price and state\n",
    "    Output:\n",
    "    return/invest ratio(float)\n",
    "    '''\n",
    "    start_price, _ = data[0]\n",
    "    end_price, _ = data[-1]\n",
    "    return (end_price - start_price)/start_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_q_learning(train_data, q, alpha, gamma, episodes):\n",
    "    '''\n",
    "    Train a Q-table \n",
    "    Inputs:\n",
    "    train_data(dataframe)\n",
    "    q(dataframe): initial Q-table\n",
    "    alpha(float): threshold of which action strategy to take\n",
    "    gamma(float): discount percentage on the future return\n",
    "    Output:\n",
    "    q(dataframe): Updated Q-table\n",
    "    actions_history(dict): has everydays' actions and close price\n",
    "    returns_since_entry(list): contains every day's return since entry\n",
    "    '''\n",
    "    actions_history = []\n",
    "    num_shares = 0\n",
    "    bought_history = []\n",
    "    returns_since_entry = [0]\n",
    "    for ii in range(episodes):\n",
    "        actions_history = []\n",
    "        num_shares = 0\n",
    "        bought_history = []\n",
    "        returns_since_entry = [0]\n",
    "        days=[0]\n",
    "        for i, val in enumerate(train_data):\n",
    "            current_adj_close, state = val\n",
    "            try:\n",
    "                next_adj_close, next_state = train_data[i+1]\n",
    "            except:\n",
    "                break\n",
    "\n",
    "            if len(bought_history) > 0:\n",
    "                returns_since_entry.append(get_return_since_entry(bought_history, current_adj_close)) \n",
    "            else:\n",
    "                returns_since_entry.append(returns_since_entry[-1])\n",
    "\n",
    "            # decide action\n",
    "            if alpha > 0.1:\n",
    "                alpha = alpha/(i+1)\n",
    "            action = act(state, q, threshold=alpha, actions_size=3)\n",
    "\n",
    "            # get reward\n",
    "            if action == 0: # hold\n",
    "                if num_shares > 0:\n",
    "                    prev_adj_close, _ = train_data[i-1]\n",
    "                    future = next_adj_close - current_adj_close \n",
    "                    past = current_adj_close - prev_adj_close\n",
    "                    reward = past\n",
    "                else:\n",
    "                    reward = 0\n",
    "\n",
    "            if action == 1: # buy\n",
    "                reward = 0\n",
    "                num_shares += 1\n",
    "                bought_history.append((current_adj_close))\n",
    "\n",
    "            if action == 2: # sell\n",
    "                if num_shares > 0:\n",
    "                    bought_price = bought_history[0]\n",
    "                    reward = (current_adj_close - bought_price)\n",
    "                    bought_history.pop(0)\n",
    "                    num_shares -= 1\n",
    "\n",
    "                else:\n",
    "                    reward = -100\n",
    "            actions_history.append((i, current_adj_close, action))\n",
    "            \n",
    "            # update q table\n",
    "            q.loc[state, action] = (1.-alpha)*q.loc[state, action] + alpha*(reward+gamma*(q.loc[next_state].max()))\n",
    "    print('End of Training!')\n",
    "    return q, actions_history, returns_since_entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Raw input from Yahoo Finance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = datetime.datetime(2014, 1, 1)\n",
    "end = datetime.datetime(2018, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train and test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = d.get_stock_data('AAPL', start, end, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Action Definition (= Q table columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_actions = {0:'hold', 1:'buy', 2:'sell'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Further formatting of the raw stock data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create_df = normalized predictors norm_bb_width, norm_adj_close, norm_close_sma_ratio\n",
    "train_df = d.create_df(train_df, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get_states = States Dictionary after discretizing by converting continuous values to integer state\n",
    "price_states_value, bb_states_value, close_sma_ratio_states_value = d.get_states(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create_state_df =  Add state information to the DF\n",
    "train_df = d.create_state_df(train_df, price_states_value, bb_states_value, close_sma_ratio_states_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Return a list of strings representing the combination of all the states\n",
    "all_states = d.get_all_states(price_states_value, bb_states_value, close_sma_ratio_states_value)\n",
    "states_size = len(all_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = d.create_df(test_df, 3)\n",
    "test_df = d.create_state_df(test_df, price_states_value, bb_states_value, close_sma_ratio_states_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (Optional) Visualizing the processed raw input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_df['norm_bb_width'], bins=50);\n",
    "plt.title('Distribution of Normalized Bollinger Band Width');\n",
    "plt.ylabel('Count');\n",
    "plt.xlabel('Normalized Bollinger Band Width');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparation of the Q Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_init = initialize_q_mat(all_states, all_actions)/1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = np.array(train_df[['norm_adj_close', 'state']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Training!\n"
     ]
    }
   ],
   "source": [
    "q, train_actions_history, train_returns_since_entry = train_q_learning(train_data, q_init, alpha=0.8, gamma=0.95, episodes=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# start_date = datetime.datetime(2014, 1, 1)\n",
    "# end_date = datetime.datetime(2018, 1, 1)\n",
    "# ticker = 'AAPL'\n",
    "\n",
    "def trainqlearner(start_date, end_date, ticker):\n",
    "    \n",
    "    # Split the data into train and test data set\n",
    "    train_df, test_df = d.get_stock_data(ticker, start_date, end_date, 0.8)\n",
    "    \n",
    "    # Action Definition (= Q table columns)\n",
    "    all_actions = {0:'hold', 1:'buy', 2:'sell'}\n",
    "    \n",
    "    # create_df = normalized predictors norm_bb_width, norm_adj_close, norm_close_sma_ratio\n",
    "    train_df = d.create_df(train_df, 3)\n",
    "    \n",
    "    # get_states = States Dictionary after discretizing by converting continuous values to integer state\n",
    "    price_states_value, bb_states_value, close_sma_ratio_states_value = d.get_states(train_df)\n",
    "    \n",
    "    # Create_state_df =  Add state information to the DF\n",
    "    train_df = d.create_state_df(train_df, price_states_value, bb_states_value, close_sma_ratio_states_value)\n",
    "    \n",
    "    # Return a list of strings representing the combination of all the states\n",
    "    all_states = d.get_all_states(price_states_value, bb_states_value, close_sma_ratio_states_value)\n",
    "    states_size = len(all_states)\n",
    "    \n",
    "    # Test Data\n",
    "    test_df = d.create_df(test_df, 3)\n",
    "    test_df = d.create_state_df(test_df, price_states_value, bb_states_value, close_sma_ratio_states_value)\n",
    "    \n",
    "    # Preparation of the Q Table\n",
    "    q_init = initialize_q_mat(all_states, all_actions)/1e9\n",
    "    train_data = np.array(train_df[['norm_adj_close', 'state']])\n",
    "    q, train_actions_history, train_returns_since_entry = train_q_learning(train_data, q_init, alpha=0.8, gamma=0.95, episodes=1)\n",
    "    \n",
    "    # Specify quantiles\n",
    "    BB_quantiles = bb_states_value\n",
    "    SMA_ratio_quantiles = close_sma_ratio_states_value\n",
    "    \n",
    "    return q, bb_states_value, SMA_ratio_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                   0             1             2\n",
       " states                                          \n",
       " 000     7.923054e-20  3.791257e-05 -3.333333e+00\n",
       " 001     6.360420e-19  6.831046e-19  5.184628e-19\n",
       " 002     8.387308e-19  4.722765e-19  3.393158e-19\n",
       " 003     8.671463e-19  4.941789e-19  7.723234e-19\n",
       " 004     2.078500e-19  5.947187e-19  9.134590e-19\n",
       " ...              ...           ...           ...\n",
       " 995     4.285178e-20  5.034515e-19  9.708147e-19\n",
       " 996     2.384491e-19  7.948143e-20  6.936294e-19\n",
       " 997     8.121146e-19  6.435647e-19  7.866062e-19\n",
       " 998     1.434855e-19  6.845854e-21  3.248093e-19\n",
       " 999     1.403554e-21  2.837145e-19  2.813702e-19\n",
       " \n",
       " [1000 rows x 3 columns],\n",
       " {0: 0.21214993537268417,\n",
       "  1: 0.32270573028866867,\n",
       "  2: 0.4141318397242567,\n",
       "  3: 0.5275312365359759,\n",
       "  4: 0.6609220163722532,\n",
       "  5: 0.7977595863851787,\n",
       "  6: 0.9684618698836707,\n",
       "  7: 1.1920723825937096,\n",
       "  8: 1.565273588970272,\n",
       "  9: 4.516587677725118},\n",
       " {0: 0.9912023931418018,\n",
       "  1: 0.9978297094902528,\n",
       "  2: 1.0006645385372122,\n",
       "  3: 1.0030697263546748,\n",
       "  4: 1.0047882912726616,\n",
       "  5: 1.007167379389267,\n",
       "  6: 1.0089983737878696,\n",
       "  7: 1.0121082535284789,\n",
       "  8: 1.016219960248148,\n",
       "  9: 1.0527113573852114})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date = datetime.datetime(2014, 1, 1)\n",
    "end_date = datetime.datetime(2018, 1, 1)\n",
    "ticker = 'AAPL'\n",
    "\n",
    "q, bb_states_value, SMA_ratio_quantiles = trainqlearner(start_date, end_date, ticker)\n",
    "\n",
    "q, bb_states_value, SMA_ratio_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_ml",
   "language": "python",
   "name": "nlp_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
